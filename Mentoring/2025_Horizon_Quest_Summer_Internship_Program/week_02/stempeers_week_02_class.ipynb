{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Week 2: Python Fundamentals for AI/ML\n",
        "**Duration:** 1 Hour  \n",
        "**Target:** Advanced High School Students\n",
        "\n",
        "## Learning Objectives\n",
        "By the end of this session, students will be able to:\n",
        "- Read and write files using Python's built-in functions and pandas\n",
        "- Create and use Python classes for data organization\n",
        "- Generate basic visualizations using matplotlib, seaborn, and plotly\n",
        "- Perform data manipulation operations using pandas with real-world datasets\n",
        "\n",
        "---\n",
        "\n",
        "## Part 1: File Operations (15 minutes)\n",
        "\n",
        "### 1.1 Built-in File Operations\n",
        "\n",
        "```python\n",
        "# Reading a text file\n",
        "with open('data.txt', 'r') as file:\n",
        "    content = file.read()\n",
        "    print(content)\n",
        "\n",
        "# Writing to a file\n",
        "data = [\"Name,Age,Score\", \"Alice,16,95\", \"Bob,17,87\", \"Charlie,16,92\"]\n",
        "with open('students.csv', 'w') as file:\n",
        "    for line in data:\n",
        "        file.write(line + '\\n')\n",
        "\n",
        "# Reading line by line (memory efficient)\n",
        "with open('students.csv', 'r') as file:\n",
        "    for line in file:\n",
        "        print(line.strip())\n",
        "```\n",
        "\n",
        "### 1.2 File Operations with Pandas\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "# Reading different file formats\n",
        "df_csv = pd.read_csv('students.csv')\n",
        "df_excel = pd.read_excel('data.xlsx', sheet_name='Sheet1')\n",
        "df_json = pd.read_json('data.json')\n",
        "\n",
        "# Writing files\n",
        "df.to_csv('output.csv', index=False)\n",
        "df.to_excel('output.xlsx', index=False, sheet_name='Results')\n",
        "df.to_json('output.json', orient='records')\n",
        "\n",
        "# Reading with specific parameters\n",
        "df = pd.read_csv('messy_data.csv',\n",
        "                 sep=';',           # Different separator\n",
        "                 skiprows=2,        # Skip first 2 rows\n",
        "                 na_values=['N/A', 'NULL'],  # Custom null values\n",
        "                 dtype={'ID': str}) # Specify data types\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Part 2: Python Classes for Data Science (15 minutes)\n",
        "\n",
        "### 2.1 Basic Class Structure\n",
        "\n",
        "```python\n",
        "class Student:\n",
        "    def __init__(self, name, age, grades):\n",
        "        self.name = name\n",
        "        self.age = age\n",
        "        self.grades = grades\n",
        "    \n",
        "    def calculate_average(self):\n",
        "        return sum(self.grades) / len(self.grades)\n",
        "    \n",
        "    def add_grade(self, grade):\n",
        "        self.grades.append(grade)\n",
        "    \n",
        "    def get_letter_grade(self):\n",
        "        avg = self.calculate_average()\n",
        "        if avg >= 90: return 'A'\n",
        "        elif avg >= 80: return 'B'\n",
        "        elif avg >= 70: return 'C'\n",
        "        elif avg >= 60: return 'D'\n",
        "        else: return 'F'\n",
        "\n",
        "# Usage\n",
        "student1 = Student(\"Alice\", 16, [95, 87, 92])\n",
        "print(f\"Average: {student1.calculate_average():.2f}\")\n",
        "print(f\"Letter Grade: {student1.get_letter_grade()}\")\n",
        "```\n",
        "\n",
        "### 2.2 Advanced Class Example for ML\n",
        "\n",
        "```python\n",
        "class DataProcessor:\n",
        "    def __init__(self, filepath):\n",
        "        self.filepath = filepath\n",
        "        self.data = None\n",
        "        self.processed_data = None\n",
        "    \n",
        "    def load_data(self):\n",
        "        \"\"\"Load data from file\"\"\"\n",
        "        self.data = pd.read_csv(self.filepath)\n",
        "        print(f\"Loaded {len(self.data)} rows\")\n",
        "        return self\n",
        "    \n",
        "    def clean_data(self):\n",
        "        \"\"\"Remove null values and duplicates\"\"\"\n",
        "        if self.data is not None:\n",
        "            initial_rows = len(self.data)\n",
        "            self.data = self.data.dropna().drop_duplicates()\n",
        "            print(f\"Cleaned data: {initial_rows} -> {len(self.data)} rows\")\n",
        "        return self\n",
        "    \n",
        "    def normalize_column(self, column):\n",
        "        \"\"\"Normalize a numeric column to 0-1 range\"\"\"\n",
        "        if column in self.data.columns:\n",
        "            min_val = self.data[column].min()\n",
        "            max_val = self.data[column].max()\n",
        "            self.data[f'{column}_normalized'] = (self.data[column] - min_val) / (max_val - min_val)\n",
        "        return self\n",
        "    \n",
        "    def get_summary(self):\n",
        "        \"\"\"Get data summary\"\"\"\n",
        "        return self.data.describe()\n",
        "\n",
        "# Method chaining example\n",
        "processor = DataProcessor('student_data.csv')\n",
        "summary = processor.load_data().clean_data().normalize_column('score').get_summary()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Part 3: Data Visualization (15 minutes)\n",
        "\n",
        "### 3.1 Matplotlib Basics\n",
        "\n",
        "```python\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Basic plotting\n",
        "x = np.linspace(0, 10, 100)\n",
        "y = np.sin(x)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(x, y, label='sin(x)', linewidth=2)\n",
        "plt.xlabel('X values')\n",
        "plt.ylabel('Y values')\n",
        "plt.title('Sine Wave')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "# Multiple subplots\n",
        "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
        "\n",
        "# Subplot 1: Line plot\n",
        "axes[0,0].plot(x, np.sin(x))\n",
        "axes[0,0].set_title('Sine')\n",
        "\n",
        "# Subplot 2: Scatter plot\n",
        "axes[0,1].scatter(np.random.randn(100), np.random.randn(100), alpha=0.6)\n",
        "axes[0,1].set_title('Random Scatter')\n",
        "\n",
        "# Subplot 3: Histogram\n",
        "axes[1,0].hist(np.random.normal(0, 1, 1000), bins=30, alpha=0.7)\n",
        "axes[1,0].set_title('Normal Distribution')\n",
        "\n",
        "# Subplot 4: Bar plot\n",
        "categories = ['A', 'B', 'C', 'D']\n",
        "values = [23, 45, 56, 78]\n",
        "axes[1,1].bar(categories, values, color=['red', 'green', 'blue', 'orange'])\n",
        "axes[1,1].set_title('Category Comparison')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "### 3.2 Introduction to Seaborn\n",
        "\n",
        "```python\n",
        "import seaborn as sns\n",
        "\n",
        "# Set style\n",
        "sns.set_style(\"whitegrid\")\n",
        "\n",
        "# Sample data\n",
        "tips = sns.load_dataset(\"tips\")\n",
        "\n",
        "# Basic plots\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "# Subplot 1: Distribution plot\n",
        "plt.subplot(1, 3, 1)\n",
        "sns.histplot(tips['total_bill'], kde=True)\n",
        "plt.title('Total Bill Distribution')\n",
        "\n",
        "# Subplot 2: Relationship plot\n",
        "plt.subplot(1, 3, 2)\n",
        "sns.scatterplot(data=tips, x='total_bill', y='tip', hue='time')\n",
        "plt.title('Bill vs Tip by Time')\n",
        "\n",
        "# Subplot 3: Box plot\n",
        "plt.subplot(1, 3, 3)\n",
        "sns.boxplot(data=tips, x='day', y='total_bill')\n",
        "plt.title('Bill Distribution by Day')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Correlation heatmap\n",
        "numeric_cols = tips.select_dtypes(include=[np.number])\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(numeric_cols.corr(), annot=True, cmap='coolwarm', center=0)\n",
        "plt.title('Correlation Matrix')\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "### 3.3 Introduction to Plotly\n",
        "\n",
        "```python\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "\n",
        "# Interactive scatter plot\n",
        "fig = px.scatter(tips, x='total_bill', y='tip',\n",
        "                 color='time', size='size',\n",
        "                 hover_data=['day'],\n",
        "                 title='Interactive Tip Analysis')\n",
        "fig.show()\n",
        "\n",
        "# 3D scatter plot\n",
        "fig = go.Figure(data=[go.Scatter3d(\n",
        "    x=np.random.randn(100),\n",
        "    y=np.random.randn(100),\n",
        "    z=np.random.randn(100),\n",
        "    mode='markers',\n",
        "    marker=dict(\n",
        "        size=12,\n",
        "        color=np.random.randn(100),\n",
        "        colorscale='Viridis',\n",
        "        opacity=0.6\n",
        "    )\n",
        ")])\n",
        "fig.update_layout(title='3D Scatter Plot')\n",
        "fig.show()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Part 4: Advanced Pandas Data Manipulation (15 minutes)\n",
        "\n",
        "### 4.1 DataFrame Creation and Basic Operations\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Creating sample dataset\n",
        "np.random.seed(42)\n",
        "data = {\n",
        "    'student_id': range(1, 101),\n",
        "    'name': [f'Student_{i}' for i in range(1, 101)],\n",
        "    'age': np.random.randint(15, 19, 100),\n",
        "    'grade': np.random.choice(['A', 'B', 'C', 'D'], 100, p=[0.2, 0.3, 0.3, 0.2]),\n",
        "    'math_score': np.random.randint(60, 100, 100),\n",
        "    'science_score': np.random.randint(65, 98, 100),\n",
        "    'english_score': np.random.randint(70, 95, 100),\n",
        "    'city': np.random.choice(['New York', 'Los Angeles', 'Chicago', 'Houston'], 100)\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "print(df.head())\n",
        "print(f\"\\nDataset shape: {df.shape}\")\n",
        "print(f\"\\nData types:\\n{df.dtypes}\")\n",
        "```\n",
        "\n",
        "### 4.2 Data Filtering and Selection\n",
        "\n",
        "```python\n",
        "# Boolean indexing\n",
        "high_performers = df[df['math_score'] > 85]\n",
        "print(f\"High performers in math: {len(high_performers)}\")\n",
        "\n",
        "# Multiple conditions\n",
        "excellent_students = df[(df['math_score'] > 90) & (df['science_score'] > 90)]\n",
        "print(f\"Excellent in both math and science: {len(excellent_students)}\")\n",
        "\n",
        "# Using query method (more readable)\n",
        "top_students = df.query('math_score > 85 and age < 17')\n",
        "print(f\"Young high performers: {len(top_students)}\")\n",
        "\n",
        "# Selecting specific columns\n",
        "scores_only = df[['name', 'math_score', 'science_score', 'english_score']]\n",
        "\n",
        "# Using loc and iloc\n",
        "specific_students = df.loc[df['city'] == 'New York', ['name', 'math_score']]\n",
        "first_10_rows = df.iloc[:10, 1:4]  # First 10 rows, columns 1-3\n",
        "```\n",
        "\n",
        "### 4.3 Data Transformation and Feature Engineering\n",
        "\n",
        "```python\n",
        "# Creating new columns\n",
        "df['total_score'] = df['math_score'] + df['science_score'] + df['english_score']\n",
        "df['average_score'] = df['total_score'] / 3\n",
        "df['performance_category'] = pd.cut(df['average_score'],\n",
        "                                   bins=[0, 70, 80, 90, 100],\n",
        "                                   labels=['Below Average', 'Average', 'Good', 'Excellent'])\n",
        "\n",
        "# Apply functions\n",
        "def categorize_age(age):\n",
        "    if age <= 16:\n",
        "        return 'Younger'\n",
        "    else:\n",
        "        return 'Older'\n",
        "\n",
        "df['age_group'] = df['age'].apply(categorize_age)\n",
        "\n",
        "# Lambda functions\n",
        "df['math_percentile'] = df['math_score'].rank(pct=True) * 100\n",
        "\n",
        "# String operations\n",
        "df['name_length'] = df['name'].str.len()\n",
        "df['name_upper'] = df['name'].str.upper()\n",
        "```\n",
        "\n",
        "### 4.4 Groupby Operations and Aggregations\n",
        "\n",
        "```python\n",
        "# Basic groupby\n",
        "city_stats = df.groupby('city').agg({\n",
        "    'math_score': ['mean', 'std', 'count'],\n",
        "    'science_score': ['mean', 'max', 'min'],\n",
        "    'age': 'mean'\n",
        "}).round(2)\n",
        "\n",
        "print(\"City-wise Statistics:\")\n",
        "print(city_stats)\n",
        "\n",
        "# Multiple grouping variables\n",
        "grade_city_stats = df.groupby(['grade', 'city'])['average_score'].agg(['mean', 'count'])\n",
        "print(\"\\nGrade and City Statistics:\")\n",
        "print(grade_city_stats)\n",
        "\n",
        "# Custom aggregation functions\n",
        "def score_range(scores):\n",
        "    return scores.max() - scores.min()\n",
        "\n",
        "custom_stats = df.groupby('city').agg({\n",
        "    'math_score': [score_range, 'mean'],\n",
        "    'total_score': ['sum', 'count']\n",
        "})\n",
        "\n",
        "# Transform operations (keep original dataframe size)\n",
        "df['city_avg_math'] = df.groupby('city')['math_score'].transform('mean')\n",
        "df['math_vs_city_avg'] = df['math_score'] - df['city_avg_math']\n",
        "```\n",
        "\n",
        "### 4.5 Pivot Tables and Reshaping\n",
        "\n",
        "```python\n",
        "# Pivot table\n",
        "pivot_grades = pd.pivot_table(df,\n",
        "                             values=['math_score', 'science_score'],\n",
        "                             index='city',\n",
        "                             columns='grade',\n",
        "                             aggfunc='mean',\n",
        "                             fill_value=0).round(2)\n",
        "\n",
        "print(\"Pivot Table - Scores by City and Grade:\")\n",
        "print(pivot_grades)\n",
        "\n",
        "# Melting (wide to long format)\n",
        "score_columns = ['math_score', 'science_score', 'english_score']\n",
        "df_melted = pd.melt(df,\n",
        "                   id_vars=['student_id', 'name', 'city'],\n",
        "                   value_vars=score_columns,\n",
        "                   var_name='subject',\n",
        "                   value_name='score')\n",
        "\n",
        "print(\"\\nMelted DataFrame (first 10 rows):\")\n",
        "print(df_melted.head(10))\n",
        "\n",
        "# Cross-tabulation\n",
        "crosstab = pd.crosstab(df['city'], df['performance_category'], normalize='columns')\n",
        "print(\"\\nCross-tabulation (City vs Performance):\")\n",
        "print(crosstab.round(3))\n",
        "```\n",
        "\n",
        "### 4.6 Handling Missing Data and Advanced Operations\n",
        "\n",
        "```python\n",
        "# Introduce some missing values for demonstration\n",
        "df_with_missing = df.copy()\n",
        "missing_indices = np.random.choice(df.index, size=20, replace=False)\n",
        "df_with_missing.loc[missing_indices, 'math_score'] = np.nan\n",
        "\n",
        "# Handling missing values\n",
        "print(f\"Missing values per column:\\n{df_with_missing.isnull().sum()}\")\n",
        "\n",
        "# Fill missing values\n",
        "df_filled = df_with_missing.copy()\n",
        "df_filled['math_score'].fillna(df_filled['math_score'].mean(), inplace=True)\n",
        "\n",
        "# Forward fill and backward fill\n",
        "df_filled['math_score_ffill'] = df_with_missing['math_score'].fillna(method='ffill')\n",
        "df_filled['math_score_bfill'] = df_with_missing['math_score'].fillna(method='bfill')\n",
        "\n",
        "# Interpolation\n",
        "df_filled['math_score_interp'] = df_with_missing['math_score'].interpolate()\n",
        "\n",
        "# Detecting outliers using IQR\n",
        "Q1 = df['math_score'].quantile(0.25)\n",
        "Q3 = df['math_score'].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "lower_bound = Q1 - 1.5 * IQR\n",
        "upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "outliers = df[(df['math_score'] < lower_bound) | (df['math_score'] > upper_bound)]\n",
        "print(f\"\\nOutliers in math scores: {len(outliers)}\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Practical Exercise (In-Class Demo)\n",
        "\n",
        "### Complete Example: Student Performance Analysis\n",
        "\n",
        "```python\n",
        "# Load and explore data\n",
        "df = pd.read_csv('student_data.csv')  # Assume this file exists\n",
        "print(\"Dataset Overview:\")\n",
        "print(df.info())\n",
        "print(\"\\nFirst few rows:\")\n",
        "print(df.head())\n",
        "\n",
        "# Data cleaning\n",
        "df_clean = df.dropna()\n",
        "df_clean = df_clean[df_clean['age'].between(15, 19)]  # Remove unrealistic ages\n",
        "\n",
        "# Feature engineering\n",
        "df_clean['total_score'] = df_clean[['math', 'science', 'english']].sum(axis=1)\n",
        "df_clean['avg_score'] = df_clean['total_score'] / 3\n",
        "\n",
        "# Analysis\n",
        "print(\"\\nPerformance by City:\")\n",
        "city_performance = df_clean.groupby('city')['avg_score'].agg(['mean', 'std', 'count'])\n",
        "print(city_performance)\n",
        "\n",
        "# Visualization\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "# Distribution of average scores\n",
        "axes[0,0].hist(df_clean['avg_score'], bins=20, alpha=0.7, color='skyblue')\n",
        "axes[0,0].set_title('Distribution of Average Scores')\n",
        "axes[0,0].set_xlabel('Average Score')\n",
        "\n",
        "# Scores by city\n",
        "df_clean.boxplot(column='avg_score', by='city', ax=axes[0,1])\n",
        "axes[0,1].set_title('Score Distribution by City')\n",
        "\n",
        "# Correlation heatmap\n",
        "score_cols = ['math', 'science', 'english', 'avg_score']\n",
        "corr_matrix = df_clean[score_cols].corr()\n",
        "im = axes[1,0].imshow(corr_matrix, cmap='coolwarm', aspect='auto')\n",
        "axes[1,0].set_xticks(range(len(score_cols)))\n",
        "axes[1,0].set_yticks(range(len(score_cols)))\n",
        "axes[1,0].set_xticklabels(score_cols)\n",
        "axes[1,0].set_yticklabels(score_cols)\n",
        "axes[1,0].set_title('Correlation Matrix')\n",
        "\n",
        "# Add correlation values\n",
        "for i in range(len(score_cols)):\n",
        "    for j in range(len(score_cols)):\n",
        "        axes[1,0].text(j, i, f'{corr_matrix.iloc[i,j]:.2f}',\n",
        "                      ha='center', va='center')\n",
        "\n",
        "# Scatter plot\n",
        "axes[1,1].scatter(df_clean['math'], df_clean['science'], alpha=0.6)\n",
        "axes[1,1].set_xlabel('Math Score')\n",
        "axes[1,1].set_ylabel('Science Score')\n",
        "axes[1,1].set_title('Math vs Science Scores')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Key Takeaways\n",
        "\n",
        "1. **File Operations**: Use context managers (`with` statement) for safe file handling\n",
        "2. **Classes**: Organize related data and functions together for better code structure\n",
        "3. **Visualization**: Choose the right plot type for your data story\n",
        "4. **Pandas**: Master filtering, grouping, and transformation operations for effective data analysis\n",
        "5. **Best Practices**: Always explore your data first, handle missing values appropriately, and validate your results\n",
        "\n",
        "---\n",
        "\n",
        "## Next Week Preview\n",
        "\n",
        "- Introduction to NumPy for numerical computing\n",
        "- Statistical analysis and hypothesis testing\n",
        "- Introduction to machine learning concepts\n",
        "- Building your first predictive model\n",
        "\n",
        "---\n",
        "\n",
        "## Additional Resources\n",
        "\n",
        "- **Pandas Documentation**: https://pandas.pydata.org/docs/\n",
        "- **Matplotlib Tutorials**: https://matplotlib.org/tutorials/\n",
        "- **Seaborn Gallery**: https://seaborn.pydata.org/examples/\n",
        "- **Plotly Python**: https://plotly.com/python/\n",
        "\n",
        "---\n",
        "\n",
        "**Remember**: The best way to learn data science is by doing. Practice with real datasets and don't be afraid to experiment!"
      ],
      "metadata": {
        "id": "ctnd92UgG6HH"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7HgaReQ7G6tL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}